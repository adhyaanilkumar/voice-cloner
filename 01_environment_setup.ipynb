{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adhyaanilkumar/voice-cloner/blob/adhya-branch/01_environment_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EX8pFTQ_jJnf",
        "outputId": "315ae8ab-7ec9-4eb7-9cc9-d63731796f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  3 07:51:07 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy scipy librosa matplotlib unidecode inflect tqdm tensorboard\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UnRI8sIWj_cl",
        "outputId": "4e44b657-7af6-41f6-aade-bb932c059223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio\n",
        "print(\"torch\", torch.__version__, \"cuda?\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lHXCPMnfkIEw",
        "outputId": "e6519d30-9f54-4f55-e46b-a528375d0382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch 2.8.0+cu126 cuda? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/tacotron2\n",
        "!git clone https://github.com/NVIDIA/waveglow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0ToPvTMrkbC0",
        "outputId": "8f0633bd-1e10-4c00-a7fd-741f6476b8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tacotron2'...\n",
            "remote: Enumerating objects: 412, done.\u001b[K\n",
            "remote: Total 412 (delta 0), reused 0 (delta 0), pack-reused 412 (from 1)\u001b[K\n",
            "Receiving objects: 100% (412/412), 2.70 MiB | 7.20 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "Cloning into 'waveglow'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 196 (delta 2), reused 2 (delta 0), pack-reused 190 (from 1)\u001b[K\n",
            "Receiving objects: 100% (196/196), 437.57 KiB | 1.44 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "t2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub','nvidia_tacotron2',pretrained=True).eval()\n",
        "wg = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub','nvidia_waveglow',pretrained=True)\n",
        "wg = wg.remove_weightnorm(wg)\n",
        "print(\"Loaded Tacotron2 & WaveGlow.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xp3kXt9XkiFL",
        "outputId": "cfe0f199-fec7-4dd7-e135-0b7cc5ae7dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  warnings.warn(\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  warnings.warn(\n",
            "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/tacotron2_pyt_ckpt_fp32/versions/19.09.0/files/nvidia_tacotron2pyt_fp32_20190427\n",
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
            "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/waveglow_ckpt_fp32/versions/19.09.0/files/nvidia_waveglowpyt_fp32_20190427\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Tacotron2 & WaveGlow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/Colab Notebooks/voice-cloner\"  # <- your folder\n",
        "RAW_ROOT   = f\"{BASE}/data/raw\"\n",
        "CLEAN_ROOT = f\"{BASE}/data/clean\"\n",
        "\n",
        "import os\n",
        "os.makedirs(RAW_ROOT, exist_ok=True)\n",
        "os.makedirs(CLEAN_ROOT, exist_ok=True)\n",
        "\n",
        "%cd \"$BASE\"\n",
        "!pwd && ls -la\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNYXUAcZ-jDb",
        "outputId": "1fe99d60-3827-4dc0-91a5-2ae1140f64c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/voice-cloner\n",
            "/content/drive/MyDrive/Colab Notebooks/voice-cloner\n",
            "total 27\n",
            "-rw------- 1 root root 8998 Sep  6 17:02 01_environment_setup.ipynb\n",
            "drwx------ 4 root root 4096 Sep  6 17:02 data\n",
            "drwx------ 2 root root 4096 Sep  6 16:39 .git\n",
            "-rw------- 1 root root 4895 Sep  5 12:52 .gitignore\n",
            "-rw------- 1 root root 1092 Sep  5 12:52 LICENSE\n",
            "-rw------- 1 root root 2581 Sep  5 12:52 README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, numpy as np\n",
        "import librosa, soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "TARGET_SR = 22050\n",
        "TOP_DB = 20\n",
        "PEAK = 0.95\n",
        "\n",
        "def process_one(in_wav, out_wav):\n",
        "    y, sr = librosa.load(in_wav, sr=None, mono=True)\n",
        "    if sr != TARGET_SR:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=TARGET_SR)\n",
        "    y, _ = librosa.effects.trim(y, top_db=TOP_DB)\n",
        "    if y.size == 0:\n",
        "        return False\n",
        "    m = np.max(np.abs(y))\n",
        "    if m > 0:\n",
        "        y = y / m * PEAK\n",
        "    os.makedirs(os.path.dirname(out_wav), exist_ok=True)\n",
        "    sf.write(out_wav, y, TARGET_SR, subtype=\"PCM_16\")\n",
        "    return True\n",
        "\n",
        "def mirror_clean(raw_root, clean_root):\n",
        "    print(f\"mirror_clean: Searching in raw_root: {raw_root}\") # Added print\n",
        "    files = glob.glob(f\"{raw_root}/**/*.wav\", recursive=True)\n",
        "    print(\"Found\", len(files), \"files\")\n",
        "    if len(files) > 0: # Added print for sample files\n",
        "        print(\"Sample raw files found:\", files[:5])\n",
        "    ok, skip = 0, 0\n",
        "    for f in tqdm(files, desc=\"Standardizing\"):\n",
        "        rel = os.path.relpath(f, raw_root)\n",
        "        out = os.path.join(clean_root, os.path.splitext(rel)[0] + \".wav\")\n",
        "        if ok < 5: # Added print for sample output paths\n",
        "            print(f\"Processing {f} -> Saving to {out}\")\n",
        "        try:\n",
        "            if process_one(f, out):\n",
        "                ok += 1\n",
        "            else:\n",
        "                skip += 1\n",
        "        except Exception as e:\n",
        "            skip += 1\n",
        "            print(\"Error:\", f, e)\n",
        "    print(f\"Done. Wrote {ok}, skipped {skip}.\")\n",
        "\n",
        "print(f\"Calling mirror_clean with raw_root: {RAW_ROOT}\")\n",
        "mirror_clean(RAW_ROOT, CLEAN_ROOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf2mA4Qn-3VT",
        "outputId": "b2c8a998-36fc-4ef1-bd73-78e69e77f840"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling mirror_clean with raw_root: /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw\n",
            "mirror_clean: Searching in raw_root: /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw\n",
            "Found 2638 files\n",
            "Sample raw files found: ['/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0184.wav', '/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0186.wav', '/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0187.wav', '/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0192.wav', '/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0183.wav']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Standardizing:   0%|          | 4/2638 [00:00<01:24, 31.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0184.wav -> Saving to /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0184.wav\n",
            "Processing /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0186.wav -> Saving to /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0186.wav\n",
            "Processing /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0187.wav -> Saving to /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0187.wav\n",
            "Processing /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0192.wav -> Saving to /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0192.wav\n",
            "Processing /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/wavs/LJ004-0183.wav -> Saving to /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0183.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Standardizing: 100%|██████████| 2638/2638 [01:18<00:00, 33.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Wrote 2638, skipped 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, csv, glob\n",
        "\n",
        "EMO_MAP = {\n",
        "    \"Amused\":\"amused\", \"Angry\":\"angry\", \"Disgusted\":\"disgusted\",\n",
        "    \"Neutral\":\"neutral\", \"Sleepy\":\"sleepy\"\n",
        "}\n",
        "\n",
        "MANIFEST = f\"{BASE}/manifests\"\n",
        "os.makedirs(MANIFEST, exist_ok=True)\n",
        "MANIFEST_CSV = f\"{MANIFEST}/manifest.csv\"\n",
        "\n",
        "rows = []\n",
        "\n",
        "# LJSpeech\n",
        "lj_clean = f\"{CLEAN_ROOT}/LJSpeech-1.1\"\n",
        "lj_raw_meta = f\"{RAW_ROOT}/LJSpeech-1.1/metadata.csv\"\n",
        "print(f\"Checking for LJSpeech metadata at: {lj_raw_meta}\") # Added print\n",
        "if os.path.exists(lj_raw_meta):\n",
        "    print(\"LJSpeech metadata found. Processing LJSpeech data.\") # Added print\n",
        "    with open(lj_raw_meta, \"r\", encoding=\"utf-8\") as f:\n",
        "        rdr = csv.reader(f, delimiter=\"|\")\n",
        "        for wid, text, norm in rdr:\n",
        "            wav = f\"{lj_clean}/wavs/{wid}.wav\"\n",
        "            if os.path.exists(wav):\n",
        "                rows.append([wav, (norm or text).strip(), \"lj\", \"neutral\", \"train\"])\n",
        "else:\n",
        "    print(f\"LJSpeech metadata not found at {lj_raw_meta}. Skipping LJSpeech processing.\") # Added print\n",
        "\n",
        "\n",
        "# Emotions\n",
        "def sidecar_text(path_wo_ext):\n",
        "    for ext in (\".txt\",\".lab\",\".trs\"):\n",
        "        p = path_wo_ext + ext\n",
        "        if os.path.exists(p):\n",
        "            try:\n",
        "                return open(p, \"r\", encoding=\"utf-8\").read().strip()\n",
        "            except:\n",
        "                pass\n",
        "    return \"\"\n",
        "\n",
        "emo_root = f\"{CLEAN_ROOT}/emotion\"\n",
        "print(f\"Checking for emotion data in clean directory: {emo_root}\") # Added print\n",
        "if os.path.isdir(emo_root):\n",
        "    print(\"Clean emotion directory found. Processing emotion data.\") # Added print\n",
        "    for speaker in sorted(os.listdir(emo_root)):\n",
        "        sp_dir = f\"{emo_root}/{speaker}\"\n",
        "        if not os.path.isdir(sp_dir):\n",
        "            continue\n",
        "        for emo_folder in sorted(os.listdir(sp_dir)):\n",
        "            emo = EMO_MAP.get(emo_folder, None)\n",
        "            if emo is None:\n",
        "                continue\n",
        "            wavs = sorted(glob.glob(f\"{sp_dir}/{emo_folder}/**/*.wav\", recursive=True))\n",
        "            print(f\"Found {len(wavs)} emotion wav files in {sp_dir}/{emo_folder}\") # Added print\n",
        "            for i, w in enumerate(wavs):\n",
        "                text = sidecar_text(os.path.splitext(w)[0])\n",
        "                if not text: # Added print if text is empty\n",
        "                    print(f\"Warning: No sidecar text found for {w}. Skipping or using empty text.\") # Decide how to handle empty text\n",
        "                split = \"val\" if i % 20 == 0 else \"train\"\n",
        "                rows.append([w, text, speaker, emo, split])\n",
        "else:\n",
        "    print(f\"Clean emotion directory not found at {emo_root}. Skipping emotion processing.\") # Added print\n",
        "\n",
        "print(f\"Total rows collected for manifest: {len(rows)}\") # Added print\n",
        "\n",
        "with open(MANIFEST_CSV, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\"path\",\"text\",\"speaker\",\"emotion\",\"split\"])\n",
        "    w.writerows(rows)\n",
        "\n",
        "len(rows), MANIFEST_CSV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZFU6nwC_6tu",
        "outputId": "5292815a-4397-42b0-cf5f-7f0a04459bf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for LJSpeech metadata at: /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/metadata.csv\n",
            "LJSpeech metadata not found at /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw/LJSpeech-1.1/metadata.csv. Skipping LJSpeech processing.\n",
            "Checking for emotion data in clean directory: /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/emotion\n",
            "Clean emotion directory not found at /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/emotion. Skipping emotion processing.\n",
            "Total rows collected for manifest: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,\n",
              " '/content/drive/MyDrive/Colab Notebooks/voice-cloner/manifests/manifest.csv')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "\n",
        "print(\"Raw root:\", RAW_ROOT)\n",
        "print(\"Clean root:\", CLEAN_ROOT)\n",
        "\n",
        "# Check how many files were standardized\n",
        "clean_wavs = glob.glob(f\"{CLEAN_ROOT}/**/*.wav\", recursive=True)\n",
        "print(\"Number of clean wavs:\", len(clean_wavs))\n",
        "print(\"First few:\", clean_wavs[:5])\n",
        "\n",
        "# Check if LJSpeech metadata exists\n",
        "print(\"LJSpeech metadata present?\", os.path.exists(f\"{RAW_ROOT}/LJSpeech-1.1/metadata.csv\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbJk6VCuAiBO",
        "outputId": "141320fc-1e7b-4923-af68-451d30bc4d86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw root: /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/raw\n",
            "Clean root: /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean\n",
            "Number of clean wavs: 2638\n",
            "First few: ['/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0184.wav', '/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0186.wav', '/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0187.wav', '/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0192.wav', '/content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/LJSpeech-1.1/wavs/LJ004-0183.wav']\n",
            "LJSpeech metadata present? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66c165db",
        "outputId": "b843749a-0098-4cde-9ecb-55dece7995a6"
      },
      "source": [
        "import os, glob\n",
        "\n",
        "print(\"Checking for files in emotion directory:\")\n",
        "emotion_wavs = glob.glob(f\"{CLEAN_ROOT}/emotion/**/*.wav\", recursive=True)\n",
        "print(f\"Found {len(emotion_wavs)} wav files in {CLEAN_ROOT}/emotion\")\n",
        "if len(emotion_wavs) > 0:\n",
        "    print(\"First 5 emotion wav files:\", emotion_wavs[:5])\n",
        "    print(\"\\nChecking sidecar text for the first emotion file:\")\n",
        "    first_emotion_wav_path = emotion_wavs[0]\n",
        "    first_emotion_text = sidecar_text(os.path.splitext(first_emotion_wav_path)[0])\n",
        "    print(f\"Text for {first_emotion_wav_path}: '{first_emotion_text}'\")\n",
        "else:\n",
        "    print(\"No emotion wav files found. Please check if the emotion dataset is correctly placed in the raw data directory and the cleaning process ran successfully.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for files in emotion directory:\n",
            "Found 0 wav files in /content/drive/MyDrive/Colab Notebooks/voice-cloner/data/clean/emotion\n",
            "No emotion wav files found. Please check if the emotion dataset is correctly placed in the raw data directory and the cleaning process ran successfully.\n"
          ]
        }
      ]
    }
  ]
}